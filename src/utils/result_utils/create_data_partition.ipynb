{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data_silo's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "folder_path = \"/proj/sourasb-220503/FedMEM/dataset/clients/data_silo/A1/100\"\n",
    "new_path = \"/proj/sourasb-220503/FedMEM/dataset/clients/data_silo/A1/20\"\n",
    "data_silo=0.2\n",
    "# Load the dataset\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('training.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        train_df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "        dir_name = filename[:12]\n",
    "        target_path = new_path + \"/\" + dir_name\n",
    "        if not os.path.exists(target_path):\n",
    "            os.makedirs(target_path)\n",
    "            print(f\"Created directory: {target_path}\")\n",
    "\n",
    "\n",
    "        # Assuming train_df is your initial DataFrame\n",
    "        num_samples = int(len(train_df)*data_silo)  # 50% of the total data\n",
    "\n",
    "        dataframes = []  # This will store your 5 DataFrames\n",
    "\n",
    "        for i in range(5):\n",
    "            # Shuffle train_df\n",
    "            shuffled_df = shuffle(train_df, random_state=None)  # Random state None for different shuffle each time\n",
    "            \n",
    "            # Take the first 50% of the shuffled DataFrame\n",
    "            subset_df = shuffled_df.iloc[:num_samples]\n",
    "            \n",
    "            # Add the subset to your list of DataFrames\n",
    "            dataframes.append(subset_df)\n",
    "            \n",
    "            # Define a file name for the current DataFrame\n",
    "            file_name = f\"Client_ID_training_{i}.csv\"\n",
    "            file_path = os.path.join(target_path, file_name)\n",
    "            # Save the DataFrame to a CSV file\n",
    "            subset_df.to_csv(file_path, index=False, header=False)\n",
    "            \n",
    "            print(f\"Saved DataFrame {i} to {file_path}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To copy the validation set to all data silo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "source_path = \"/proj/sourasb-220503/FedMEM/dataset/clients/data_silo/A1/100\"\n",
    "new_path = \"/proj/sourasb-220503/FedMEM/dataset/clients/data_silo/A1/20\"\n",
    "\n",
    "# Copy the file\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('validation.csv'):\n",
    "        file_path = os.path.join(source_path, filename)\n",
    "\n",
    "        dir_name = filename[:12]\n",
    "        target_path = new_path + \"/\" + dir_name \n",
    "        if not os.path.exists(target_path):\n",
    "            os.makedirs(target_path)\n",
    "            print(f\"Created directory: {target_path}\")\n",
    "        destination_path = target_path + \"/\" +filename\n",
    "        shutil.copy(file_path, target_path)\n",
    "        print(f\"File copied from {source_path} to {destination_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed. The files have been saved to the '20' directory.\n"
     ]
    }
   ],
   "source": [
    "# The path to the directory containing your CSV files\n",
    "input_directory = '/proj/sourasb-220503/FedMEM/dataset/clients/A1'\n",
    "# The path to the directory where you want to save the new CSV files\n",
    "output_directory = '/proj/sourasb-220503/FedMEM/dataset/clients/data_silo/A1/20'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# List all CSV files in the input directory\n",
    "csv_files = glob.glob(os.path.join(input_directory, '*.csv'))\n",
    "\n",
    "# Process each file\n",
    "for file_path in csv_files:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Select 20% of the rows sequentially\n",
    "    num_rows = len(df)\n",
    "    subset_df = df.iloc[:int(num_rows * 0.2)]\n",
    "\n",
    "    # Define the new file path in the output directory\n",
    "    # Extract the file name from the original path and prepend the output directory path\n",
    "    file_name = os.path.basename(file_path)\n",
    "    new_file_path = os.path.join(output_directory, file_name)\n",
    "\n",
    "    # Save the new DataFrame to a CSV file in the output directory\n",
    "    subset_df.to_csv(new_file_path, index=False)\n",
    "\n",
    "print(\"Processing completed. The files have been saved to the '20' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Client_ID_training_2.csv - Rows: 43\n",
      "File: Client_ID_training_3.csv - Rows: 43\n",
      "File: Client_ID_training_0.csv - Rows: 43\n",
      "File: Client_ID_training_1.csv - Rows: 43\n",
      "File: Client_ID_16_validation.csv - Rows: 55\n",
      "File: Client_ID_training_4.csv - Rows: 43\n"
     ]
    }
   ],
   "source": [
    "# The path to the directory where the new CSV files are saved\n",
    "directory = '/proj/sourasb-220503/FedMEM/dataset/clients/data_silo/A1/20/Client_ID_16'\n",
    "\n",
    "# List all CSV files in the output directory\n",
    "csv_files = glob.glob(os.path.join(directory, '*.csv'))\n",
    "\n",
    "# Process each file\n",
    "for file_path in csv_files:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Get the number of rows in the DataFrame\n",
    "    num_rows = len(df)\n",
    "\n",
    "    # Print the file name and the number of rows it contains\n",
    "    print(f'File: {os.path.basename(file_path)} - Rows: {num_rows}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find identical rows accross all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Client_ID_training_2.csv</th>\n",
       "      <th>Client_ID_training_3.csv</th>\n",
       "      <th>Client_ID_training_0.csv</th>\n",
       "      <th>Client_ID_training_1.csv</th>\n",
       "      <th>Client_ID_23_validation.csv</th>\n",
       "      <th>Client_ID_training_4.csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Client_ID_training_2.csv</th>\n",
       "      <td>173.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Client_ID_training_3.csv</th>\n",
       "      <td>142.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Client_ID_training_0.csv</th>\n",
       "      <td>136.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Client_ID_training_1.csv</th>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Client_ID_23_validation.csv</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Client_ID_training_4.csv</th>\n",
       "      <td>140.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Client_ID_training_2.csv  \\\n",
       "Client_ID_training_2.csv                        173.0   \n",
       "Client_ID_training_3.csv                        142.0   \n",
       "Client_ID_training_0.csv                        136.0   \n",
       "Client_ID_training_1.csv                        137.0   \n",
       "Client_ID_23_validation.csv                       0.0   \n",
       "Client_ID_training_4.csv                        140.0   \n",
       "\n",
       "                             Client_ID_training_3.csv  \\\n",
       "Client_ID_training_2.csv                        142.0   \n",
       "Client_ID_training_3.csv                        173.0   \n",
       "Client_ID_training_0.csv                        141.0   \n",
       "Client_ID_training_1.csv                        134.0   \n",
       "Client_ID_23_validation.csv                       0.0   \n",
       "Client_ID_training_4.csv                        138.0   \n",
       "\n",
       "                             Client_ID_training_0.csv  \\\n",
       "Client_ID_training_2.csv                        136.0   \n",
       "Client_ID_training_3.csv                        141.0   \n",
       "Client_ID_training_0.csv                        173.0   \n",
       "Client_ID_training_1.csv                        138.0   \n",
       "Client_ID_23_validation.csv                       0.0   \n",
       "Client_ID_training_4.csv                        134.0   \n",
       "\n",
       "                             Client_ID_training_1.csv  \\\n",
       "Client_ID_training_2.csv                        137.0   \n",
       "Client_ID_training_3.csv                        134.0   \n",
       "Client_ID_training_0.csv                        138.0   \n",
       "Client_ID_training_1.csv                        173.0   \n",
       "Client_ID_23_validation.csv                       0.0   \n",
       "Client_ID_training_4.csv                        138.0   \n",
       "\n",
       "                             Client_ID_23_validation.csv  \\\n",
       "Client_ID_training_2.csv                             0.0   \n",
       "Client_ID_training_3.csv                             0.0   \n",
       "Client_ID_training_0.csv                             0.0   \n",
       "Client_ID_training_1.csv                             0.0   \n",
       "Client_ID_23_validation.csv                         55.0   \n",
       "Client_ID_training_4.csv                             0.0   \n",
       "\n",
       "                             Client_ID_training_4.csv  \n",
       "Client_ID_training_2.csv                        140.0  \n",
       "Client_ID_training_3.csv                        138.0  \n",
       "Client_ID_training_0.csv                        134.0  \n",
       "Client_ID_training_1.csv                        138.0  \n",
       "Client_ID_23_validation.csv                       0.0  \n",
       "Client_ID_training_4.csv                        173.0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "directory = '/proj/sourasb-220503/FedMEM/dataset/clients/data_silo/A1/80/Client_ID_23'  # Adjust this to your directory\n",
    "\n",
    "# List all CSV files in the directory\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files = glob.glob(os.path.join(directory, '*.csv'))\n",
    "file_names = [os.path.basename(f) for f in csv_files]\n",
    "\n",
    "overlap_matrix = pd.DataFrame(np.zeros((len(csv_files), len(csv_files))), columns=file_names, index=file_names)\n",
    "\n",
    "\n",
    "# Compare each file with every other file in the list\n",
    "for i in range(len(csv_files)):\n",
    "    for j in range(i, len(csv_files)):\n",
    "        df1 = pd.read_csv(csv_files[i], names=['file', 'score'])\n",
    "        df2 = pd.read_csv(csv_files[j], names=['file', 'score'])\n",
    "\n",
    "        # Find overlapping rows\n",
    "        overlap = pd.merge(df1, df2, how='inner')\n",
    "\n",
    "        overlap_count = len(overlap)\n",
    "\n",
    "        # Print the number of overlapping rows\n",
    "        #print(f'Overlap between {os.path.basename(csv_files[i])} and {os.path.basename(csv_files[j])}: {len(overlap)} rows')\n",
    "        overlap_matrix.iloc[i, j] = overlap_count\n",
    "        overlap_matrix.iloc[j, i] = overlap_count  # Mirror the count since the matrix is symmetric\n",
    "\n",
    "# Display the overlap matrix\n",
    "overlap_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personalized_fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
