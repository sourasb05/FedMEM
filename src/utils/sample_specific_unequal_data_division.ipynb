{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_list_with_sum(n, total_sum, min_value, max_value):\n",
    "    \"\"\"Generate a list of 'n' integers with a specific total sum and within a given range.\"\"\"\n",
    "    # Check if it's possible to create such a list\n",
    "    if n * min_value > total_sum or n * max_value < total_sum:\n",
    "        return None\n",
    "    \n",
    "    elements = []\n",
    "    remaining_sum = total_sum\n",
    "    for i in range(n - 1):\n",
    "        max_possible_value = min(max_value, remaining_sum - (n - i - 1) * min_value)\n",
    "        min_possible_value = max(min_value, remaining_sum - (n - i - 1) * max_value)\n",
    "        value = random.randint(min_possible_value, max_possible_value)\n",
    "        elements.append(value)\n",
    "        remaining_sum -= value\n",
    "\n",
    "    # Add the last element\n",
    "    elements.append(remaining_sum)\n",
    "\n",
    "    return elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[929, 1377, 1140, 1422, 1251, 804, 778, 1326, 958, 668]\n",
      "10653\n",
      "0\n",
      "929\n",
      "929\n",
      "2306\n",
      "2306\n",
      "3446\n",
      "3446\n",
      "4868\n",
      "4868\n",
      "6119\n",
      "6119\n",
      "6923\n",
      "6923\n",
      "7701\n",
      "7701\n",
      "9027\n",
      "9027\n",
      "9985\n",
      "9985\n",
      "10653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/proj/sourasb-220503/FedMEM/dataset/unequal_division/client_1.csv',\n",
       " '/proj/sourasb-220503/FedMEM/dataset/unequal_division/client_2.csv',\n",
       " '/proj/sourasb-220503/FedMEM/dataset/unequal_division/client_3.csv',\n",
       " '/proj/sourasb-220503/FedMEM/dataset/unequal_division/client_4.csv',\n",
       " '/proj/sourasb-220503/FedMEM/dataset/unequal_division/client_5.csv',\n",
       " '/proj/sourasb-220503/FedMEM/dataset/unequal_division/client_6.csv',\n",
       " '/proj/sourasb-220503/FedMEM/dataset/unequal_division/client_7.csv',\n",
       " '/proj/sourasb-220503/FedMEM/dataset/unequal_division/client_8.csv',\n",
       " '/proj/sourasb-220503/FedMEM/dataset/unequal_division/client_9.csv',\n",
       " '/proj/sourasb-220503/FedMEM/dataset/unequal_division/client_10.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = \"/proj/sourasb-220503/FedMEM/dataset/tensor_train_val_1.csv\"\n",
    "\n",
    "# Read the CSV data into a DataFrame\n",
    "df_csv = pd.read_csv(csv_file)\n",
    "n_client = 10\n",
    "min_value = 500\n",
    "max_value = 1500\n",
    "# Divide the DataFrame into 5 sequential parts and save to files\n",
    "num_rows = len(df_csv)\n",
    "division_size = generate_list_with_sum(n_client, num_rows, min_value, max_value)\n",
    "print(division_size)\n",
    "print(sum(division_size))\n",
    "# Initialize the start index for the first file\n",
    "start_idx = 0\n",
    "\n",
    "# List to keep track of generated file paths\n",
    "generated_files = []\n",
    "\n",
    "for i in range(n_client):\n",
    "    # Calculate end index for slicing, ensure not to exceed the DataFrame's length\n",
    "    end_idx = min(start_idx + division_size[i], num_rows) if i < n_client else num_rows  # Adjust for the last file to include all remaining rows\n",
    "    print(start_idx)\n",
    "    print(end_idx)\n",
    "    # Slice the DataFrame\n",
    "    sliced_df = df_csv.iloc[start_idx:end_idx]\n",
    "    \n",
    "    # Generate filename and save the sliced DataFrame to CSV\n",
    "    filename = f\"/proj/sourasb-220503/FedMEM/dataset/unequal_division/client_{i+1}.csv\"\n",
    "    sliced_df.to_csv(filename, index=False)\n",
    "    \n",
    "    # Update the start index for the next file\n",
    "    start_idx = end_idx\n",
    "    \n",
    "    # Add filename to the list of generated files\n",
    "    generated_files.append(filename)\n",
    "\n",
    "generated_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove repeated entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows removed: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the CSV file\n",
    "csv_file_path = '/proj/sourasb-220503/FedMEM/dataset/unequal_division/client_2.csv'  # Replace 'your_csv_file.csv' with the path to your CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Step 2 & 3: Find and remove duplicate entries\n",
    "# By default, `drop_duplicates()` keeps the first occurrence and removes subsequent duplicates\n",
    "cleaned_df = df.drop_duplicates()\n",
    "\n",
    "# Optional: If you want to check how many duplicates were found\n",
    "num_duplicates = len(df) - len(cleaned_df)\n",
    "print(f\"Number of duplicate rows removed: {num_duplicates}\")\n",
    "\n",
    "# Step 4: Save the cleaned DataFrame to a new CSV file, if desired\n",
    "cleaned_csv_file_path = csv_file_path # Replace 'cleaned_csv_file.csv' with your desired path\n",
    "cleaned_df.to_csv(cleaned_csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check file exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All image files exist.\n",
      "Missing image files:\n",
      "Series([], Name: image_file_name, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specify the CSV file path and the folder path containing the images\n",
    "csv_file_path = '/proj/sourasb-220503/FedMEM/dataset/unequal_division/client_10.csv'  # Replace this with the path to your CSV file\n",
    "image_folder_path = '/proj/sourasb-220503/FedMEM/dataset/r3_refined'  # Replace this with the path to your folder containing the images\n",
    "\n",
    "# Step 1: Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Step 2 & 3: Iterate through the DataFrame and check for each image file's existence\n",
    "file_existence = []  # List to keep track of file existence\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    image_file_name = row['name']  # Replace 'image_file_column' with the actual column name\n",
    "    image_file_path = os.path.join(image_folder_path, image_file_name)\n",
    "    \n",
    "    # Check if the image file exists and append the result to the list\n",
    "    file_exists = os.path.exists(image_file_path)\n",
    "    file_existence.append({'image_file_name': image_file_name, 'exists': file_exists})\n",
    "\n",
    "# Convert the list to a DataFrame for better visualization (optional)\n",
    "existence_df = pd.DataFrame(file_existence)\n",
    "\n",
    "# Display the results\n",
    "# print(existence_df)\n",
    "\n",
    "# Assuming existence_df is your DataFrame with 'image_file_name' and 'exists' columns\n",
    "all_exist = existence_df['exists'].all()\n",
    "\n",
    "if all_exist:\n",
    "    print(\"All image files exist.\")\n",
    "else:\n",
    "    print(\"Some image files do not exist.\")\n",
    "\n",
    "# Filter the DataFrame to get only the rows where 'exists' is False\n",
    "missing_files_df = existence_df[existence_df['exists'] == False]\n",
    "\n",
    "# Display the names of the missing image files\n",
    "print(\"Missing image files:\")\n",
    "print(missing_files_df['image_file_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the original DataFrame to exclude rows where 'exists' is False\n",
    "df = df[~df['name'].isin(missing_files_df['image_file_name'])]\n",
    "\n",
    "# Optionally, save the cleaned DataFrame back to a new CSV file\n",
    "#cleaned_csv_file_path = 'cleaned_csv_file.csv'  # Replace with your desired output file path\n",
    "df.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (3261818382.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    Expected Dimension of Features : 2048x7x7\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "\"\"\"|\"\"\"\n",
    "\n",
    "Class Model():\n",
    "  def __init__(self):\n",
    "      resnet = torchvision.models.resnet50(pretrained=True)\n",
    "      self.avgpool = nn.Sequential(list(resnet.children())[-2])\n",
    "\n",
    "  def forward(self, input):\n",
    "      features_1d = self.avgpool(input)\n",
    "      x = linear(features_1d) # output - 512\n",
    "      x = relu(x)\n",
    "      x = linear(x) # output - 256\n",
    "      x = relu(x)\n",
    "\n",
    "Expected Dimension of Features : 2048x7x7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personalized_fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
